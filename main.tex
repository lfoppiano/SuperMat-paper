% \documentclass[a4paper,10pt]{article}
% \usepackage[utf8]{inputenc}
% \usepackage{authblk}
% \usepackage{tabularx}
% \usepackage{url}
% \usepackage{graphicx}
% \graphicspath{{images/}}
% \usepackage{caption}
% \usepackage{subcaption}
% \usepackage{multirow}
% \usepackage{multicol}
% \usepackage{listings}
% \usepackage{placeins}


%%%

\documentclass[]{interact}

\usepackage{epstopdf}% To incorporate .eps illustrations using PDFLaTeX, etc.
\usepackage[caption=false]{subfig}% Support for small, `sub' figures and tables
%\usepackage[nolists,tablesfirst]{endfloat}% To `separate' figures and tables from text if required
%\usepackage[doublespacing]{setspace}% To produce a `double spaced' document if required
%\setlength\parindent{24pt}% To increase paragraph indentation when line spacing is doubled

\usepackage[numbers,sort&compress]{natbib}% Citation support using natbib.sty
\bibpunct[, ]{[}{]}{,}{n}{,}{,}% Citation support using natbib.sty
\renewcommand\bibfont{\fontsize{10}{12}\selectfont}% Bibliography support using natbib.sty
\makeatletter% @ becomes a letter
\def\NAT@def@citea{\def\@citea{\NAT@separator}}% Suppress spaces between citations using natbib.sty
\makeatother% @ becomes a symbol again

\theoremstyle{plain}% Theorem-like structures provided by amsthm.sty
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}

\theoremstyle{remark}
\newtheorem{remark}{Remark}
\newtheorem{notation}{Notation}

\usepackage{url}
\graphicspath{{images/}}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{tabularx}

\begin{document}

\articletype{RESEARCH PAPER}% Specify the article type or omit as appropriate

\title{SuperMat: Construction of a linked annotated dataset from superconductors-related publications}


\author{
\name{Luca Foppiano\textsuperscript{a}\thanks{Corresponding authors: FOPPIANO.Luca@nims.go.jp, ISHII.Masashi@nims.go.jp}, Sae Dieb\textsuperscript{a}, Akira Suzuki\textsuperscript{a}, Pedro Baptista de Castro\textsuperscript{b}, Suguru Iwasaki\textsuperscript{b}, Azusa Uzuki\textsuperscript{b}, Miren Garbine Esparza Echevarria\textsuperscript{b}, Yan Meng\textsuperscript{b}, Kensei Terashima\textsuperscript{b}, Laurent Romary\textsuperscript{c}, Yoshihiko Takano\textsuperscript{b}, Masashi Ishii\textsuperscript{a}}
\affil{\textsuperscript{a}Material Database Group, MaDIS, NIMS, Tsukuba, 305-0044, Japan; 
\textsuperscript{b}Nano Frontier Superconducting Materials Group, MANA, NIMS, Tsukuba, 305-0047, Japan;
\textsuperscript{c}ALMAnaCH, Inria, Paris, 75012, France}
}

\maketitle

%%%%

% \title{SuperMat: Construction of a linked annotated dataset from superconductors-related publications}

% \author[1*]{Luca Foppiano}
% \author[1]{Sae Dieb}
% \author[1]{Akira Suzuki}
% \author[2]{Pedro Baptista de Castro}
% \author[2]{Suguru Iwasaki}
% \author[2]{Azusa Uzuki}
% \author[2]{Miren Garbine Esparza Echevarria}
% \author[2]{Yan Meng}
% \author[2]{Kensei Terashima}
% \author[3]{Laurent Romary}
% \author[2]{Yoshihiko Takano}
% \author[1*]{Masashi Ishii}

% \affil[1]{Material Database Group, MaDIS, NIMS, Tsukuba, 305-0044, Japan}
% \affil[2]{Nano Frontier Superconducting Materials Group, MANA, NIMS, Tsukuba, 305-0047, Japan}
% \affil[3]{ALMAnaCH, Inria, Paris, 75012, France}

% \affil[*]{corresponding authors: Luca Foppiano (FOPPIANO.Luca@nims.go.jp), Masashi Ishii (ISHII.Masashi@nims.go.jp)}

% \begin{document}

% \flushbottom

\begin{abstract}
A growing number of papers are published in the area of superconducting materials science.
However, novel text and data mining (TDM) processes are still needed to efficiently access and exploit this accumulated knowledge, paving the way towards data-driven materials design. 
Herein, we present SuperMat (Superconductor Materials), an annotated corpus of linked data derived from scientific publications on superconductors, which comprises 142 articles, 16052 entities, and 1398 links that are characterised into six categories: the names, classes, and properties of materials; links to their respective superconducting critical temperature (\textit{T\textsubscript{c}}); and parametric conditions such as applied pressure or measurement methods.
The construction of SuperMat resulted from a fruitful collaboration between computer scientists and material scientists, and its high quality is ensured through validation by domain experts. 
The quality of the annotation guidelines was ensured by satisfactory Inter Annotator Agreement (IAA) between the annotators and the domain experts. 
SuperMat includes the dataset, annotation guidelines, and annotation support tools that use automatic suggestions to help minimise human errors.
\end{abstract}

\begin{keywords}
materials informatics, machine learning, dataset, superconductors, text and data mining
\end{keywords}

\begin{quote}
    \textbf{CLASSIFICATION}: Databases, data structure, ontology
\end{quote}


\section{Introduction}
The vast majority of scientific knowledge exists as published articles~\cite{Grigas2017JustGI, Khabsa2014TheNO, OrduaMalea2015MethodsFE, Bjrk2009ScientificJP}. 
These publications are presented mainly as text, which is challenging to be used as a machine-readable structure. 
Meanwhile, as a part of the text and data mining (TDM) discipline, computer-assisted information collection from the literature has become a supportive asset for scientific research~\cite{doi:10.1063/5.0021106}. 
In the past decades, new TDM processes were developed for several natural science disciplines to achieve automatic document processing such as information retrieval, entity extraction, and clustering.  
TDM has been applied in biology for identifing interactions between agents (e.g. bacteria, viruses, genes, and proteins)~\cite{10.1371/journal.pone.0004554, Krallinger2010, Krallinger2009ExtractionOH} to support the research on serious diseases including cancer~\cite{Krasnitz2019CancerB}. 
In chemistry, it was used for the disambiguation of chemical compounds names, synthesis extraction, and retrieval~\cite{Hawizy2011ChemicalTaggerAT}.
In both domains, the application of TDM was based on manually curated datasets (corpora) that functioned as infrastructures. Examples are the BioCreative IV CHEMDNER corpus~\cite{Krallinger2015TheCC} in chemistry, and Genia~\cite{Kim2003GENIAC} and GENETAG~\cite{Tanabe2005GENETAGAT, Ohta2009IncorporatingGA} in biology. Such datasets are crucial for developing, training, and evaluating TDM systems.

In comparison, such resources in the materials science domain are rather limited. 
Reported cases include NaDev~\cite{Dieb2016} on nanocrystal devices research, a corpus for extracting synthesis recipes~\cite{kononova_text-mined_2019}, and ChemDataExtractor~\cite{court2018auto} which focuses only on chemical entities. In the superconductors domain, we could identify MagDb~\cite{court_magnetic_2020} focusing on magnetic materials with limited information categories. Another project is SC-CoMIcs~\cite{yamaguchi-etal-2020-sc}.
SuperMat is different from SC-CoMIcs based on the following reasons: (a) it provides full papers instead of abstracts which contain more detailed information about the research on superconducting materials, and (b) it contains linked entities. 

To address this shortage of infrastructure, experimental data is extracted manually~\cite{doi:10.1021/cm400893e}, or ab-initio calculations are used~\cite{Jain2013CommentaryTM_materialsProject} but they might not accurately describe the real system.
Several challenges still hinder the data-driven exploration of materials (also called Materials Informatics (MI)), namely: the lack of data standard, infant stage of the data-driven culture, a wide variety of conflicting stakeholders, and missing incentives for researchers to contribute to large collaborative initiatives~\cite{Hill2016MaterialsSW}. 
To bridge these gaps, it is necessary to create infrastructural resources to support TDM processes in materials science through the automatic construction of databases for materials and their properties. 
Such application can minimise the need for humans to read the new papers and extract the key information therein. 
Equally importantly, it enables scientists to focus and leverage computing power and human resources to find deeper relationships between superficially unrelated information. 
Other applications include providing semantically enriched search engines that accept fine-grain queries~\cite{Liu2019SurfaceMR} to reduce the time needed to access specific information. 
These processes cannot be established without essential resources such as dictionaries, lexicons, and datasets. 

% Superconductors domain
Research on superconducting materials has been growing rapidly towards both fundamental science as well as practical applications. Superconductors display many intriguing phenomena including zero-resistivity, the ability to host a high magnetic field, quantisation of the magnetic flux, and vortex pinning.  
Current applications of superconductors include medical instruments, high-speed trains, quantum computers, and the Linear Hadron Collider (LHC)~\cite{PhilippeBook, Kizu2010ConstructionOT, Cardani2017NewAO}. 
However, discovering a new superconductor is a challenging task~\cite{PhysRevB.103.014509}. For example, in a previous work~\cite{doi:10.1088/1468-6996/16/3/033503} out of ~1000 studied materials, only 3\% were found to be superconducting. 
The National Institute for Materials Science (NIMS) in Japan has been manually constructing databases to support material research, and SuperCon (\url{http://supercon.nims.go.jp}) is a manually curated data source for the superconductor domain.
These databases would help researchers design new superconducting materials with a higher superconducting critical temperature (\textit{T\textsubscript{c}}) (ideally up to room temperature)~\cite{Hamlin2019SuperconductivityNR,stanev2017machine}.
However, the current resources are very limited and not dynamic enough to incorporate the information from new publications in a timely manner. 
In this paper, we present SuperMat (Superconductors Materials), an annotated linked corpus for superconducting material information. 
This dataset contains 142 documents with 16052 (7166 unique) entities, and 1398 links that can serve as an infrastructural data for TDM processes in the domain of superconducting materials. 
We also describe the construction guidelines for SuperMat, in the hope of supporting researchers to systematically create annotated data.
Furthermore, the unique feature of links between entities in SuperMat will allow the development of more precise methodologies to associate a particular material with its properties.

\label{sec:method}
\section{Methods}

\label{content-acquisition}
\subsection{Content acquisition}
SuperMat originates from PDF documents of scientific articles related to superconductor research. 
The PDF format is the most widely used format for scientific publications \cite{johnson2018pdfStatistics}.
The original documents were collected from the following sources: (a) the Open Access (OA) version of peer-reviewed articles referenced in the SuperCon database records; 
(b) articles provided by domain experts containing suitable items and potential links of material names, \textit{T\textsubscript{c}} values, measurement methods, and pressures; (c) articles from "condensed matter" category of arXiv (\url{https://arxiv.org/archive/cond-mat}) selected using the search terms of "superconductor", "critical temperature", and "superconductivity". 

Pre-print versions of peer-reviewed articles were obtained using a lookup service for bibliographic data called biblio-glutton (\url{https://github.com/kermitt2/biblio-glutton}) that aggregates data from various sources: the Crossref (\url{https://www.crossref.org/}) bibliographic database, the unPaywall (\url{http://unpaywall.org}) service, the PubMed Central repository (\url{https://pubmed.ncbi.nlm.nih.gov/}), and mappings to other databases. 
We queried \textit{biblio-glutton} using the bibliographic data of each article referenced in Supercon; subsequently, we downloaded the pre-print article associated with the retrieved record, if available. 
Although the published version may be different from the pre-print version of a document, the differences measured by comparing pre-print and peer-reviewed articles in biology~\cite{carneiro_comparing_2020} measured objective differences to be around 5\%.
% A record in Unpaywall does not guarantee that the downloaded article could be reused to create derivative works. Therefore, for each article that was not downloaded from arXiv, we manually verified its reusability by checking for an explicit statement of the Creative Commons licence in the PDF document or at the original publisher's page. 

\subsection{Preliminary annotation study}
\label{subsec:preliminary-annotation-study}
Preliminary annotation study was carried out to assess the effort required from the annotators to reach an acceptable Inter Annotation Agreement (IAA \textgreater 0.7) .
We annotated two randomly selected OA papers, by using a preliminary version of the guidelines with a limited tag-set of four labels: \texttt{<material>}, \texttt{<tc>} (expression describing the presence or absence of superconductivity), \texttt{<tcValue>} (value of \textit{T\textsubscript{c}}), and \texttt{<doping>} (amount of substitution, such as stochiometric values, usually expressed as functions of x or y).
The process was iterated multiple times.
Each iteration ended with computing the IAA using the Krippendorff's alpha coefficient~\cite{Krippendorff2004ReliabilityIC,Zapf2016MeasuringIR}, while annotators discussed the disagreements, and updated the guidelines.

Based on the results in Table~\ref{table:summary-preliminary-annotation}, IAA reached a satisfactory level around 0.9 after the third iteration. 
In the second iteration, although the average IAA reached 0.7 on three of the four labels, the average agreement was not satisfactory. 
When analysing the disagreement, we noticed that the low score in the \texttt{<doping>} label was caused by a heavy overlap with the \texttt{<material>} label, which required more precise definition in the guidelines. 

Based on this preliminary study, the following changes were implemented. 
(a) The label \texttt{<doping>} was merged under the \texttt{<material>} because, even with detailed documentation it was too difficult for humans to annotate them in a consistent way.
(b) Three more labels were added: measurement methods and pressure (described as parametric conditions in relation to \textit{T\textsubscript{c}}), and class of materials. 

\subsection{Tag-set design}
The tag set (also referred to as \textit{labels}) represents the classes of entities and the type of links between them, which were designed to be extracted from the text (Figure~\ref{fig:example-annotations-and-links}).

\subsubsection{Entities}
Entities (also referred as Named Entities, mentions, or surface forms) are chunks of texts that represent an information of interest, as follow: 

\begin{itemize}
\item Class (tag: \texttt{<class>}) represents a group of materials defined by certain characteristics.
Superconducting materials can be classified according to different criteria such as the composition and magnetic properties. 
Among publications collected for this study, the domain experts identified three types of classes based on: (a) the composition and crystal structure, (b) material phenomena (e.g. "I-type" and "II-type superconductivity", "BCS superconductors", "nematic", and "conventional/unconventional superconductivity"), and (c) high/low \textit{T\textsubscript{c}} value (e.g. "high-tc” superconductors). 

In this work, we only considered the (a) classes, mainly because the material composition and crystal structure do not change with time. For example, a cuprate from 1998 is still called a cuprate today. 
In comparison, many material phenomena used for (b) are not robust enough, and can be biased by the viewpoint of the author(s) or research group, or the measurement methods. 
Finally, the definition of "high-tc" superconductors (c) is completely relative; i.e., with the progress of research, materials once considered "high-tc" might not be so anymore.

\item Material (tag: \texttt{<material>}) identifies the name of one or more materials. 
This label is used to collect the following types of information: 
\begin{itemize}
    \item Chemical formula indicating the material by its general or stochiometric formula (e.g. \texttt{LaFe\textsubscript{1-x}O\textsubscript{7}}, \texttt{WB\textsubscript{2}}),
    \item Compositional name (e.g. \texttt{magnesium diboride}) or abbreviations (e.g. \texttt{YBCO}), 
    \item The material's shape (e.g. wire, powder, thin film) or form of material (e.g. single/poly crystal), 
    \item Modification by a dopant (\texttt{Zn-doped}, \texttt{Si-doped}) or by percentage of doping (\texttt{2\%-doped}). We also considered qualitative expressions such as \textit{overdoped}, \textit{lightly doped}, and \textit{pure} as valid information, 
    \item Substrate information (e.g. \texttt{grown on MgO(100) film}) when it was adjacent to the material name or formula, in the text,
    \item Additional information about the sample (e.g. \texttt{as-grown}, \texttt{untwinned}, \texttt{single-layer}) when it was adjacent to the material name or formula, in the text. 
\end{itemize}

\item Superconducting critical temperature (tag: \texttt{<tc>}) identifies expressions related to the phenomenon of superconductivity. Any temperature mentioned in the text is not necessarily the \textit{T\textsubscript{c}}. Rather, it could refer to the temperature for other processes/events such as annealing/sintering temperature, specific measurements, and structural changes.
This label identifies the presence or absence of superconductivity at a given temperature.
In addition, modifiers of this information (increasing/descreasing \textit{T\textsubscript{c}}) are also retained. 

\item Superconducting critical temperature value (tag: \texttt{<tcValue>}) represents the temperature at which the superconducting phenomenon occurs. 
It can be defined by different experimental criteria, such as the onset, mid-point of resistivity drop, or zero resistivity.
This value also considers boundary conditions, such as the \textit{onset of superconductivity}, \textit{zero resistance}. 

\item Applied pressure (tag: \texttt{<pressure>}) indicates the applied pressure corresponding to a measured \textit{T\textsubscript{c}}. 

\item The measurement method (tag: \texttt{<me\_method>}) indicates the method used to measure or calculate the presence of superconductivity. Here, we considered the following categories: resistivity, magnetic susceptibility, specific heat, and theoretical calculations. 
\end{itemize}

\subsubsection{Links}
The links connects entities of materials or samples to their corresponding properties, conditions, and results. 
The links are non-directional, and there are no restrictions on the number of links for each entity. 
We defined three types of links:

\begin{itemize}
    \item material-tc: linking materials to their \textit{T\textsubscript{c}} values.
    \item tc-pressure: connecting \textit{T\textsubscript{c}} and the applied pressure under which it was obtained.
    \item tc-me\_method: linking \textit{T\textsubscript{c}} and the corresponding measurement method. 
\end{itemize}


\subsection{Annotation guidelines}
\label{subsec:annotation-guidelines}
Annotation guidelines include the principles and the rules that describe  what constitutes as desired information for the SuperMat dataset and how to annotate it. They include detailed description of the specific rules that have been defined for each type of information to be annotated, with one or more definitions and examples illustrating what to annotate in different cases, exceptions, and references. We used an online system to track the discussions and decisions when a question or a comment was raised, and provided a link to such issues in the respective description or example. 
In addition, the guidelines include \textit{linking rules} that provide information on how to correctly connect the entities in a relationship. 
The guidelines were built using a dynamic markup language (called RestructuredText) and stored in a git (\url{https://git-scm.com/}) version control system repository. We deployed them as HTML files via web, which were updated automatically after each modification. They can be accessed at \url{https://supermat.readthedocs.io}.

\subsection{Annotation support tools}
\label{subsec:annotation-support-tool}
The task of annotating documents is tedious and requires both attention and subject knowledge from the annotators.
Annotation support tools aim to maximise the efficiency of annotators and minimise human mistakes. 
They are composed of a web-based collaborative annotation tool, automatic annotation suggestions, and automatic corpus analysis. 

\subsubsection{Web-based collaborative annotation tool: INCEpTION}
\label{subsec:annotation-tool}

The annotation tool is the platform used for creating, correcting and linking annotations.
After evaluating several tools, we selected INCEpTION~\cite{tubiblio106270,eckart-de-castilho-etal-2016-web}, a web-based multi-user platform for machine-assisted rapid dataset annotation construction. 
INCEpTION provides supportive functionalities that include: 
\begin{itemize}
    \item Multi-layer annotation sheets allow different annotation schemas over the same documents, 
    \item Two annotation steps: annotation consists of manually correcting pre-imported documents, while curation allows another user to validate the annotations (Figure~\ref{fig:inception-curation-interface}). 
    \item On-the-fly automatic suggestions based on active learning and string matching (Figure~\ref{fig:inception-curation-interface}), 
    \item Bulk annotation corrections, and 
    \item Being open-source (Apache 2.0 license), and under active development at the time of this paper (\url{https://inception-project.github.io/}).
\end{itemize}

\subsubsection{Annotation suggestions}
\label{subsec:automatic-system-prototype}

Previous works have demonstrated that annotation suggestions improve the quality of the output~\cite{Fort2010InfluenceOP,Nvol2011SemiautomaticSA,Lingren2014EvaluatingTI}.
We provide two types of annotations suggestions. 
(i) \textit{Machine-based annotated data} that were assigned to the documents before loading into the annotation tool. Here, we use a machine learning (ML)-based system from a previously implemented prototype~\cite{foppiano2019proposal} to support our tag-set. 
(ii). \textit{Active learning recommendations} provided by INCEpTION are assigned on-the-fly based on previous annotations. 
The active-learning recommendations are less precise since they aim to increase the recall, and therefore they need to be explicitly accepted by the annotator.

\subsubsection{Automatic corpus analysis}
Automatic corpus analysis is a set of scripts designed to run after the validation step. 
These scripts automatically find inconsistencies in the links and entities, while extracting the statistics of the corpus. 
We calculated the inconsistencies by examining every annotated entity and computing the frequency of the same text being annotated with different labels. 
The script outputs a summary table by visualising each annotation value, as well as their labels and frequencies.
We visually inspected this table, because the reported inconsistencies can be either obvious mistakes (Table~\ref{table:dataset-inconsistencies-clear}) or arise from ambiguities (Table~\ref{table:dataset-inconsistencies-unclear}); therefore their context should be verified. 

Although the links are conceptually non-directed, we have defined a practical convention to maintain their consistency. For example, \textit{material-tc} is always represented as a link between \texttt{<tcValue>} and \texttt{<material>} entities. 
The script also computes the statistics (Table \ref{table:summary-content}) for the number of entities (total, unique, by class), the number of links (total, intra- and inter-paragraph, between paragraphs), and other statistical information. 


\subsection{Annotation process}
\label{subsec:annotation-workflow}
The annotation workflow (Figure~\ref{fig:schema-comparison-modified-workflow}) was designed following the \textit{MATTER} (Model, Annotate, Train, Test, Evaluate, and Revise) schema\cite{pustejovsky2012natural} and other related work~\cite{Dieb2016, Krallinger2015TheCC}.
The workflow is composed of five steps (Figure~\ref{fig:schema-comparison-modified-workflow}): \textit{data-preparation}, \textit{correction}, \textit{validation}, \textit{testing and evaluation}, \textit{revision}. 
This workflow involves three main actors: the automatic process, computer scientists, and the domain experts.

The first step of the annotation process involves preparing the machine-based annotated data from the source PDF documents. 
The PDF files are converted to an XML-based format, and annotation is automatically applied. 
This is followed by four more steps: 

\begin{itemize}
\item Annotation: The human annotator can select a document and manually add, remove, or modify each entity based on rules defined in the guidelines. Once the annotation is complete, the document is marked "ready" for the validation. 

\item Validation/Curation by domain experts: Annotations from different users are validated and merged into a final document (Figure~\ref{fig:inception-curation-interface}). 
The domain expert ("curator"), can compare the different annotated versions, and select the best combination of annotations, or add new ones. 
This step ensures that the annotations are cross-checked and that the document is validated by domain experts.

\item Automatic consistency checks and statistical analysis: This step aims to discover obvious mistakes such as mislabelling or incorrect linking. 
A sequence labelling model is trained and evaluated using 10-fold cross-validation. The evaluation provides precision, recall, and f-score metrics for all the labels.
The resulting model is used for producing machine-based annotated data in the following iteration.

\item Review: Retrospective analysis of the past iteration, where unclear cases are discussed and documented in the annotation guidelines. 

\end{itemize}

\subsection{Data transformation}
\label{subsec:transformation-of-data}
There are two processes of data transformation (Figure~\ref{fig:data-transformation}): (a) from the source document (PDF) to the dataset format representation (XML-based), and (b) from the dataset format representation to the annotation tool exchange formats (\url{https://inception-project.github.io/releases/0.16.1/docs/user-guide.html\#sect_formats}) and vice-versa. 
\begin{itemize}
    \item PDF to XML-based: This step converts the PDF source document to the dataset format representation in XML following the Text Encoding Initiative (TEI, \url{https://tei-c.org/}) format guidelines. 
    Such transformation is performed by leveraging the functionalities provided by GROBID (\url{https://github.com/kermitt2/grobid}).
    
    We developed a customised process for collecting a subset of information from the source PDF document.
    The process extracts the title, keywords, and abstract from the header; and paragraphs, sections. and figure and table captions from the body.
    All the callouts to references, tables, and figures are ignored.
    The resulting structured document is then encoded in XML as will be described below. 
    \item XML to the annotation tool exchange formats: We transform our XML-formatted data into an INCEpTIONS compatible import format, such as the Webanno TSV 3.2 (\url{https://inception-project.github.io/releases/0.17.0/docs/user-guide.html\#sect_formats_webannotsv3}), and vice-versa using a set of Python scripts. 
    The Webanno TSV 3.2 format is an extension of the CONLL (\url{https://www.signll.org/conll/}) format, with additions of the header and column representation.
\end{itemize}

\section{Data Record}
\label{sec:data-record}
The dataset is composed of 142 PDF documents, of which 92\% (130) are OA (Figure~\ref{fig:arxiv-rate}).
To comply with copyright restriction, few articles from our dataset are not publicly available in our repository. 
The top three publishers represented in the corpus are American Physical Society (APS), Elsevier, and IOP Publishing (Figure~\ref{fig:distribution-by-publisher}).
Figure~\ref{fig:distribution-by-year} illustrate the distribution by publication date.
We summarise SuperMat's content in Table~\ref{table:summary-content}, with the statistics of documents, entities, and links given separately. In particular, this dataset contains 16052 (7166 unique) entities spread over six labels and 1398 links. 

Each document is encoded according to the XML TEI guidelines, which is a rich format for document representation. 
We have carried out no specific customisation, in order to remain fully compliant with the general TEI schema.
A TEI document has two main parts: the header (within the \texttt{<teiHeader>} tags) containing all the document metadata, and the body (within the section delimited by the \texttt{<text>} tag). 
The transformed data has the following structure: 

\begin{verbatim}
<TEI xml:lang="en" xmlns="http://www.tei-c.org/ns/1.0">
    <teiHeader>
        <fileDesc>
            <titleStmt>
                <title>[...]</title>
            </titleStmt>
            <publicationStmt>
                <publisher>[...]</publisher>
            </publicationStmt>
        </fileDesc>
        <encodingDesc/>
            <abstract>
                <p>[...]</p>
                <ab type="keywords">[...]</ab>
            </abstract>
        <profileDesc>
        </profileDesc>
    </teiHeader>
    <text>
        <body>
            <p>[...]</p>
            <ab type="tableCaption"> [...] </ab>
            <p> [...] </p>
            <ab type="figureCaption"> [...] </ab> 
        </body>
    </text>
</TEI>
\end{verbatim}

We transformed the source documents into these TEI-compliant structures using a simplified representation for specific content types.
The general objective is to flatten the content into a generic structure where priority is given to the annotations.
For instance, the keywords section, which groups together the key terms defined by the author(s) of the paper, is encoded using the generic tag \texttt{<ab type="keywords">} as free text, instead of the dedicated \texttt{<keywords>} element that would typically be part of the header. 
For both the abstract and the article body, the text is segmented in paragraphs (by means of the \texttt{<p>} element). 
The text is annotated with the generic \texttt{<rs>} (referencing string) element adorned with three attributes: \texttt{@type} (the entity type), \texttt{@corresp} (to provide a link to another annotation such as from \textit{material} to \textit{T\textsubscript{c}}), and \texttt{@xml:id} (to uniquely identify the annotation for referencing or linking purposes).

Because only the captions of tables and figures are retained from the original source, a simplified encoding was defined by means of the \texttt{<ab>} element characterised by a \texttt{@type} attribute; that is, \texttt{<ab type="figureCaption">} for figure captions and \texttt{<ab type="tableCaption">} for table captions. 
Here is an example: 

\begin{verbatim}
<p>
    The electron-doped high-<rs type="tc">transition-
    temperature</rs> (<rs type="tc">Tc</rs>) <rs 
    type="class">iron-based pnictide</rs> 
    superconductor <rs type="material" 
    xml:id="m6">LaFeAsO1-xHx</rs> has a unique 
    phase diagram: Superconducting (SC) double domes are 
    sandwiched by antiferromagnetic phases at ambient 
    pressure and they turn into a single dome with 
    a maximum <rs type="tc">Tc</rs> that 
    <rs type="tcValue" xml:id="m7" 
    corresp="#m6,#9">exceeds 45K</rs> 
    at a pressure of <rs type="pressure" 
    corresp="#m7">3.0 GPa</rs>. 
    [...]
</p>
\end{verbatim}

In the above snippet, the entities \textit{"3.0 GPa"}, \textit{"exceed 45K"} and \textit{"LaFeAsO1-xHx"} are linked together via the pairs \texttt{@corresp, @xml:id}. 
This schema supports multiple annotations to any part of the document. 
For example, the entity \textit{exceed 45K} has a second link with the corresponding identifier (\textit{"\#9"}) to an annotation outside this paragraph.


\section{Applications}
\label{sec:applications}
SuperMat is constructed as a resource for TDM applications in superconducting materials. It can be used as data source in several complementary tasks: 
(1) creation of an automatic information extraction system for dataset creation,
(2) articles classification, 
(3) named entity extraction (for example, automatic dictionary construction), 
(4) clustering and document synthesis,
(5) training of machine learning (ML) algorithms,
(6) evaluation of rule-based or ML-based algorithms, and 
(7) development of downstream processes, such as material name parser, or quantity normalisation.

% \subsection{Reusability}
% The data structure employed in this study (classes of materials, materials names, and related properties), is similar to that used in other domains in materials science. 
% Therefore, SuperMat can be reused to facilitate or bootstrap the creation of new TDM processes in areas of materials research besides superconductors.
% SuperMat could be used as a feature for a machine learning model for NER or EL systems in materials science such as magnetocaloric, piezoelectric, and thermoelectric domains.  

\subsection{Practical applications}
Such a dataset may benefit several types of possible applications: 

\begin{itemize}
    \item Evaluation tasks: This corpus can be used for evaluation tasks on automatic extraction. In particular, we can envision two popular tasks in superconducting materials science, namely: (a) NER and (b) EL methods. EL techniques have been mainly designed and studied using text from Wikipedia and newswires services which represent most of the available data. 
    To the best of our knowledge, however, there is no application within materials science.
    \item Automatic information extraction for superconducting materials: This dataset can be used as training data for such a purpose. 
    Automatic information extraction using ML and text mining techniques can accelerate the construction of databases for superconducting materials.
    \item Document retrieval: Information retrieval is a key application helping researchers overcome information overload.
    One way is through query expansion to cover multiple expressions of the same term. 
    By collecting and clustering all expressions under the same concept, it would be possible to retrieve documents when, for example, the resistivity measurement is described by a phrase other than "resistivity". 
    Furthermore, the assigned labels can be used to boost documents where a certain term belongs on a specific label. 
    For example, \textit{cobalt oxide} can appear as either \texttt{<material>} or \texttt{<class>} depending on the context, while a user would like to obtain documents where \textit{cobalt oxide} appears as \texttt{<material>}.
    \item Weighted-clustering: Scientific document clustering has recently gained growing attention because of its potential capacity for finding additional relevant documents of interest.
    For example, clustering can help locating similar experimental settings in a large collection of documents. However, clustering documents based on their general content might not be optimal for finding such detailed similarities.
    Annotation can be leveraged to tilt the clustering algorithm toward entity similarity, which may provide a more focused clustering towards a specific type of information.
\end{itemize}

\label{sec:technical-validation}
\section{Technical Validation} 
The following measures were employed to ensure the creation of a high-quality dataset: 
\begin{itemize}
    \item Each document was revised and validated by domain experts, 
    \item The workflow begins by assigning machine-based annotated data. This has demonstrated to improve the annotation task over several aspects, namely: time consumption, error rate, and annotation agreement~\cite{Fort2010InfluenceOP,Nvol2011SemiautomaticSA,Lingren2014EvaluatingTI}.
    \item On-the-fly automatic annotation recommendations, which provide fresh suggestions based on online decisions made by the annotators.
    \item The annotators have rapid access to changes in the annotation guidelines.
    \item The discussions were documented and linked in the guidelines. 
    \item Reviews are discussed and approved collaboratively between domain experts and other annotators.
\end{itemize}

These guidelines are a vital piece of this work since they contain knowledge accumulated from these activities.
However, measuring the completeness of the guidelines is challenging. 
Assuming that the documents validated by domain experts represent the ground truth, we conducted IAA analysis between different annotators against the ground truth, using the Krippendorf's Alpha metric~\cite{Krippendorff2004ReliabilityIC}.
Table~\ref{table:average-iaa} shows the average IAA which is satisfying with a value of approximately 0.9. 
The highest score is obtained in the \texttt{<material>} entities, while the lowest one is obtained in \texttt{<pressure>}, which appears less frequently in the papers. 
The disagreement in \texttt{<tcValue>} can appear to be too low as compared with other labels such as \texttt{<class>}, which is, at first look, more ambiguous. 
We analysed the different cases and identified three reasons why this happens. 
First, \texttt{<tcValue>} may depend heavily on the context that requires more human attention, and it is therefore more prone to errors. 
Second, our suggestions system is challenged in its ability to disambiguate critical temperatures from other temperature data, leading to incorrect or invalid suggestions. 
Finally, the presence of mathematical symbols (e.g. "\texttt{\~}", "\texttt{<}", and "\texttt{>}") or other modifiers ("\texttt{up to}", "\texttt{exceeds}", etc.) before the \texttt{<tcValue>} could generate small disagreements that accumulate in the average score. 

To more precisely isolate the impact of the guidelines, we grouped the IAA results by level of domain experience. 
Table~\ref{table:comparison-iaa-nde-de} displays the IAA between the validated data and the data corrected by (a) domain experts (researchers who conduct superconducting development experiments), (b) non-domain-experts (researchers with no experience with superconducting materials), and (c) novices (students in materials science with limited domain experience). 
Obviously, the domain experts have the highest agreement and the IAA value (around 0.95) is 0.06 higher on average than that of non-domain experts. 
Thus, superconducting materials is a complex domain that requires knowledge in materials science to produce high-quality data, while crowdsourcing initiatives such as the Amazon Mechanical Turk might not work well. 

Furthermore, we measured the reliability of the guidelines by observing how quickly novices could reach a satisfying agreement with the validation of the domain experts, without any previous training on the guidelines.
From Table~\ref{table:comparison-iaa-nde-de}, the  novices can attain high IAA results by only using the guidelines and our annotation support tools. 
The average difference in agreement with domain experts (around 0.05) indicates that the guidelines are precise and complete, and that the annotations tools offer sufficient support. 

% \section{Usage Notes}
% \label{sec:usage-notes}
% SuperMat is provided as a set of XML files, whose format is described above. 
% The dataset is maintained at the GitHub repository  \url{https://github.com/lfoppiano/SuperMat} and will be updated regularly. 
% We will roll out a release on regular basis. 
% Releases will be accessible at GitHub and at the National Institute for Materials Science (NIMS)'s Material Data Repository (MDR) platform \url{https://mdr.nims.go.jp/}, which permits DOIs to be automatically assigned to datasets.
% The current repository includes 130 OA articles, and their respective bibliographic data as reference. 
% The copyrighted articles will not be re-distributed due to their restrictive licenses.

\section{Data Availability}
\label{sec:code-availability}
The references of the original papers and their bibliographical information, the annotation guidelines sources, and the developed code are available at the GitHub repository \url{https://github.com/lfoppiano/SuperMat}. The guidelines are freely accessible at \url{https://supermat.readthedocs.io}.
The data transformation scripts were written in Python and can be run from the command line. 
They require BeautifulSoup  (\url{https://www.crummy.com/software/BeautifulSoup/}), an open-source library for parsing XML and HTML formats. 
The data analysis scripts were developed as Jupyter notebooks (\url{https://jupyter.org/}) which can easily output results and graphs in the browser. 
The open source annotation tool is INCEpTION (\url{https://inception-project.github.io/}). 
The content was acquired using biblio-glutton (\url{https://www.github.com/kermitt2/biblio-glutton}) and Grobid (\url{https://www.github.com/kermitt2/grobid}).
We computed the IAA using the Java library DkPro statistics (\url{https://dkpro.github.io/dkpro-statistics/})~\cite{Meyer2014DKProAA}.

\section{Conclusions}

In this paper we described the construction of an annotated linked dataset from scientific publications on superconductors development. 
SuperMat aims to establish a solid infrastructure where to build or improve TDM processes in superconductor materials domain.
We annotated 142 full-text articles where the data was automatically extracted from the PDF document and encoded through the XML TEI guidelines providing a basic structure of the original document. 
The dataset is validated by domain experts and provides 16052 entities of six categories, and 1398 links between materials, properties and conditions. 
This approach can be extended to other materials domains following similar methodology.


\section*{Acknowledgements}

We would like to thank Tanifuji Mikiko for her continuous support, as well as the enthusiasm and the openness with which she lead the Data PlatForm Data Center (DPFC, \url{https://www.nims.go.jp/eng/research/materials-data-pf/index.html}) at NIMS.
Our warmest thanks to Patrice Lopez, the author of Grobid (\url{https://github.com/kermitt2/grobid}) and other TDM open-source projects. 

\section*{Notes on contributors}

L.F. designed and developed the work (data preparation, annotation tools, IAA experiments, automatic annotations). M.I. and Y.T. supervised the project.
L.R. defined the standardised dataset TEI format.
L.F. S.D. A.S. A.U. M.G.E.E. P.B.C. Y.M. S.I., and K.T. performed the dataset annotation and validation.
M.G.E.E. P.B.C. Y.M. S.I. K.T., and Y.T. validated the corpus.
L.F. wrote the manuscript with assistance in editing from S.D., M.I., K.T., P.B.C., Y.M., and  M.G.E.E.. 
All authors reviewed and approved the final manuscript. 

\section*{Competing interests} 

The authors declare no competing interests.

% \begin{thebibliography}{}
% \bibitem{Grigas2017JustGI}
% Grigas, Vincas, Simona Juzeniene, and Jone Velickaite. 2017. ‘“Just Google It” - the Scope of Freely Available Information Sources for Doctoral Thesis Writing’. Inf. Res. 22.

% \bibitem{Khabsa2014TheNO}
% Khabsa, Madian, and C. Lee Giles. 2014. ‘The Number of Scholarly Documents on the Public Web’. PLoS ONE 9.

% \bibitem{OrduaMalea2015MethodsFE}
% Orduña-Malea, Enrique, Juan Manuel Ayllon, Alberto Martín-Martín, and Emilio Delgado López-Cózar. 2015. ‘Methods for Estimating the Size of Google Scholar’. Scientometrics 104: 931–49.

% \bibitem{Bjrk2009ScientificJP}
% Björk, Bo-Christer, Annikki Roos, and Mari Lauri. 2009. ‘Scientific Journal Publishing: Yearly Volume and Open Access Availability’. Inf. Res. 14.

% \bibitem{doi:10.1063/5.0021106}
% Olivetti, Elsa A., Jacqueline M. Cole, Edward Kim, Olga Kononova, Gerbrand Ceder, Thomas Yong-Jin Han, and Anna M. Hiszpanski. 2020. ‘Data-Driven Materials Research Enabled by Natural Language Processing and Information Extraction’. Applied Physics Reviews 7 (4): 041317. https://doi.org/10.1063/5.0021106.

% \bibitem{10.1371/journal.pone.0004554}
% He, Min, Yi Wang, and Wei Li. 2009. ‘PPI Finder: A Mining Tool for Human Protein-Protein Interactions’. PLOS ONE 4 (2): 1–6. https://doi.org/10.1371/journal.pone.0004554.

% \bibitem{Krallinger2010}
% Krallinger, Martin, Florian Leitner, and Alfonso Valencia. 2010. ‘Analysis of Biological Processes and Diseases Using Text Mining Approaches’. In Bioinformatics Methods in Clinical Research, 341–82. Totowa, NJ: Humana Press. https://doi.org/10.1007/978-1-60327-194-3\_16.

% \bibitem{Krallinger2009ExtractionOH}
% Krallinger, Martin, José M. G. Izarzugaza, Carlos Rodríguez Penagos, and Alfonso Valencia. 2009. ‘Extraction of Human Kinase Mutations from Literature, Databases and Genotyping Studies’. BMC Bioinformatics 10: S1–S1.

% \bibitem{Krasnitz2019CancerB}
% Krasnitz, Alexander. 2019. ‘Cancer Bioinformatics’. In Methods in Molecular Biology.

% \bibitem{Hawizy2011ChemicalTaggerAT}
% Hawizy, Lezan, David M. Jessop, Nico Adams, and Peter Murray-Rust. 2011. ‘ChemicalTagger: A Tool for Semantic Text-Mining in Chemistry’. Journal of Cheminformatics 3: 17–17.

% \bibitem{Krallinger2015TheCC}
% Krallinger, Martin, Obdulia Rabal, Florian Leitner, Miguel Vazquez, David Salgado, Zhiyong Lu, Robert Leaman, et al. 2015. ‘The CHEMDNER Corpus of Chemicals and Drugs and Its Annotation Principles’. Journal of Cheminformatics 7: S2–S2.

% \bibitem{Kim2003GENIAC}
% Kim, Jin-Dong, Tomoko Ohta, Yuka Tateisi, and Jun’ichi Tsujii. 2003. ‘GENIA Corpus - a Semantically Annotated Corpus for Bio-Textmining’. Bioinformatics 19 Suppl 1: i180-2.

% \bibitem{Tanabe2005GENETAGAT}
% Tanabe, Lorraine K., Natalie Xie, Lynne H. Thom, Wayne Matten, and W. John Wilbur. 2005. ‘GENETAG: A Tagged Corpus for Gene/Protein Named Entity Recognition’. BMC Bioinformatics 6: S3–S3.

% \bibitem{Ohta2009IncorporatingGA}
% Ohta, Tomoko, Jin-Dong Kim, Sampo Pyysalo, Yue Wang, and Jun’ichi Tsujii. 2009. ‘Incorporating GENETAG-Style Annotation to GENIA Corpus’. In BioNLP@HLT-NAACL.

% \bibitem{Dieb2016}
% Dieb, Thaer M., Masaharu Yoshioka, and Shinjiro Hara. 2016. ‘NaDev: An Annotated Corpus to Support Information Extraction from Research Papers on Nanocrystal Devices’. Journal of Information Processing 24 (January): 554–64. https://doi.org/10.2197/ipsjjip.24.554.

% \bibitem{yamaguchi-etal-2020-sc}
% Yamaguchi, Kyosuke, Ryoji Asahi, and Yutaka Sasaki. 2020. ‘SC-CoMIcs: A Superconductivity Corpus for Materials Informatics’. In Proceedings of the 12th Language Resources and Evaluation Conference, 6753–60. Marseille, France: European Language Resources Association. https://www.aclweb.org/anthology/2020.lrec-1.834.

% \bibitem{kononova_text-mined_2019}
% Kononova, Olga, Haoyan Huo, Tanjin He, Ziqin Rong, Tiago Botari, Wenhao Sun, Vahe Tshitoyan, and Gerbrand Ceder. 2019a. ‘Text-Mined Dataset of Inorganic Materials Synthesis Recipes’. Scientific Data 6 (1): 203. https://doi.org/10.1038/s41597-019-0224-1.

% \bibitem{doi:10.1021/cm400893e}
% Gaultois, Michael W., Taylor D. Sparks, Christopher K. H. Borg, Ram Seshadri, William D. Bonificio, and David R. Clarke. 2013. ‘Data-Driven Review of Thermoelectric Materials: Performance and Resource Considerations’. Chemistry of Materials 25 (15): 2911–20. https://doi.org/10.1021/cm400893e.

% \bibitem{Jain2013CommentaryTM_materialsProject}
% Jain, Anubhav, Shyue Ping Ong, Geoffroy Hautier, Wei Chen, William Davidson Richards, Stephen Dacek, Shreyas Cholia, et al. 2013. ‘The Materials Project: A Materials Genome Approach to Accelerating Materials Innovation’. APL Materials 1 (1): 011002. https://doi.org/10.1063/1.4812323.

% \bibitem{Hill2016MaterialsSW}
% Hill, J., Gregory J. Mulholland, K. Persson, R. Seshadri, C. Wolverton, and B. Meredig. 2016. ‘Materials Science with Large-Scale Data and Informatics: Unlocking New Opportunities’. Mrs Bulletin 41: 399–409.

% \bibitem{Liu2019SurfaceMR}
% Liu, Huaping, Feng Wang, Fuchun Sun, and Bin Fang. 2019. ‘Surface Material Retrieval Using Weakly Paired Cross-Modal Learning’. IEEE Transactions on Automation Science and Engineering 16: 781–91.

% \bibitem{PhilippeBook}
% Mangin, Philippe, and Rémi Kahn. 2016. Superconductivity: An Introduction. Springer. https://doi.org/10.1007/978-3-319-50527-5.

% \bibitem{Kizu2010ConstructionOT}
% Kizu, Kaname, Katsuhiko Tsuchiya, Yozo Kashiwa, Haruyuki Murakami, and Kôichi Yoshida. 2010. ‘Construction of the Jacketing Facility and First Production Results of Superconductor for JT-60SA’. IEEE Transactions on Applied Superconductivity 20: 538–42.

% \bibitem{Cardani2017NewAO}
% Cardani, Laura, Francesco Bellini, Nicola Casali, et al. 2017. ‘New Application of Superconductors: High Sensitivity Cryogenic Light Detectors’. Nuclear Instruments \& Methods in Physics Research Section A-Accelerators Spectrometers Detectors and Associated Equipment 845: 338–41.

% \bibitem{Konno2018DeepLO}
% Konno, Tomohiko, H. Kurokawa, F. Nabeshima, Y. Sakishita, Ryo Ogawa, I. Hosako, and A. Maeda. 2018. ‘Deep Learning Model for Finding New Superconductors’. ArXiv abs/1812.01995.

% \bibitem{Hamlin2019SuperconductivityNR}
% Hamlin, James J. 2019. ‘Superconductivity near Room Temperature’. Nature 569: 491–92.

% \bibitem{stanev2017machine}
% Stanev, Valentin, Corey Oses, A. Kusne, Efrain Rodriguez, Johnpierre Paglione, Stefano Curtarolo, and I. Takeuchi. 2017. ‘Machine Learning Modeling of Superconducting Critical Temperature’. Npj Computational Materials 4. https://doi.org/10.1038/s41524-018-0085-8.

% \bibitem{johnson2018pdfStatistics}
% Johnson, Duff. 2018. PDF Statistics – the Universe of Electronic Documents. THE INSTITUTE OF ELECTRONICS, INFORMATION AND COMMUNICATION ENGINEERS.

% \bibitem{carneiro_comparing_2020}
% Carneiro, Clarissa F. D., Victor G. S. Queiroz, Thiago C. Moulin, Carlos A. M. Carvalho, Clarissa B. Haas, Danielle Rayêe, David E. Henshall, et al. 2020a. ‘Comparing Quality of Reporting between Preprints and Peer-Reviewed Articles in the Biomedical Literature’. Research Integrity and Peer Review 5 (1): 16. https://doi.org/10.1186/s41073-020-00101-3.

% \bibitem{Krippendorff2004ReliabilityIC}
% Krippendorff, Klaus. 2006. ‘Reliability in Content Analysis: Some Common Misconceptions and Recommendations’. Human Communication Research 30 (3): 411–33. https://doi.org/10.1111/j.1468-2958.2004.tb00738.x.

% \bibitem{Zapf2016MeasuringIR}
% Zapf, Antonia, Stefanie Castell, Lars Morawietz, and André Karch. 2016. ‘Measuring Inter-Rater Reliability for Nominal Data – Which Coefficients and Confidence Intervals Are Appropriate?’ BMC Medical Research Methodology 16 (1): 93. https://doi.org/10.1186/s12874-016-0200-9.

% \bibitem{tubiblio106270}
% Klie, Jan-Christoph, Michael Bugert, Beto Boullosa, Richard Eckart de Castilho, and Iryna Gurevych. 2018. ‘The INCEpTION Platform: Machine-Assisted and Knowledge-Oriented Interactive Annotation’. In Proceedings of the 27th International Conference on Computational Linguistics: System Demonstrations, 5–9. Association for Computational Linguistics. http://tubiblio.ulb.tu-darmstadt.de/106270/.

% \bibitem{eckart-de-castilho-etal-2016-web}
% Eckart de Castilho, Richard, Éva Mújdricza-Maydt, Seid Muhie Yimam, Silvana Hartmann, Iryna Gurevych, Anette Frank, and Chris Biemann. 2016. ‘A Web-Based Tool for the Integrated Annotation of Semantic and Syntactic Structures’. In Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH), 76–84. Osaka, Japan: The COLING 2016 Organizing Committee. https://www.aclweb.org/anthology/W16-4011.

% \bibitem{Fort2010InfluenceOP}
% Fort, Karën, and Benoît Sagot. 2010. ‘Influence of Pre-Annotation on POS-Tagged Corpus Development’. In Proceedings of the Fourth Linguistic Annotation Workshop, 56–63. Uppsala, Sweden: Association for Computational Linguistics. https://www.aclweb.org/anthology/W10-1807.

% \bibitem{Nvol2011SemiautomaticSA}
% Névéol, Aurélie, Rezarta Islamaj Dogan, and Zhiyong Lu. 2011. ‘Semi-Automatic Semantic Annotation of PubMed Queries: A Study on Quality, Efficiency, Satisfaction’. Journal of Biomedical Informatics 44 2: 310–18.

% \bibitem{Lingren2014EvaluatingTI}
% Lingren, Todd, Louise Deleger, Katalin Molnar, Haijun Zhai, Jareen Meinzen-Derr, Megan Kaiser, Laura Stoutenborough, Qi Li, and Imre Solti. 2014. ‘Evaluating the Impact of Pre-Annotation on Annotation Speed and Potential Bias: Natural Language Processing Gold Standard Development for Clinical Named Entity Recognition in Clinical Trial Announcements’. Journal of the American Medical Informatics Association: JAMIA 21 (3): 406–13. https://doi.org/10.1136/amiajnl-2013-001837.

% \bibitem{foppiano2019proposal}
% Foppiano, Luca, Thaer M. Dieb, Akira Suzuki, and Ishii Masashi. 2019. ‘Proposal for Automatic Extraction Framework of Superconductors Related Information from Scientific Literature’. THE INSTITUTE OF ELECTRONICS, INFORMATION AND COMMUNICATION ENGINEERS.

% \bibitem{pustejovsky2012natural}
% Pustejovsky, James, and Amber Stubbs. 2012. Natural Language Annotation for Machine Learning: A Guide to Corpus-Building for Applications.  O’Reilly Media, Inc.

% \bibitem{Meyer2014DKProAA}
% Meyer, Christian M., Margot Mieskes, Christian Stab, and Iryna Gurevych. 2014. ‘DKPro Agreement: An Open-Source Java Library for Measuring Inter-Rater Agreement’. In Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: System Demonstrations, 105–9. Dublin, Ireland: Dublin City University and Association for Computational Linguistics. https://www.aclweb.org/anthology/C14-2023.

% \bibitem{Kotegawa2009ContrastingPE}
% Kotegawa, H., T. Kawazoe, H. Tou, K. Murata, H. Ogino, K. Kishio, and J. Shimoyama. 2009. ‘Contrasting Pressure Effects in Sr2VFeAsO3 and Sr2ScFePO3’. ArXiv: Superconductivity.

% \bibitem{Yonezawa2004NewO}
% Yonezawa, Shigeki, Y. Muraoka, and Z. Hiroi. 2004. ‘New SS-Pyrochlore Oxide Superconductor CsOs2O6’. Journal of the Physical Society of Japan 73: 1655–56.


% \end{thebibliography}{}


\bibliographystyle{tfnlm}
\bibliography{references}  

\section*{Figures \& Tables}

\begin{figure}[ht]
  \centering
  \includegraphics[width=\linewidth]{example-annotated-corpus-postprocess.png}
  \caption{Example in the annotated corpus. The excerpt was taken from~\cite{Kotegawa2009ContrastingPE}.}
  \label{fig:example-annotations-and-links}
\end{figure}


\begin{table}[ht]
    \tbl{Summary of the IAA for each annotation iteration.}
    {\begin{tabular}{ ccc } 
    \toprule
        \textbf{Iteration} \# & \textbf{IAA} & \textbf{IAA by label}  \\ [0.5ex] 
    \midrule
        1  & 0.45
        &\begin{tabular}{  cc  } 
            \texttt{<material>} & 0.45\\ 
            \texttt{<tc>} & 0.56\\
            \texttt{<tcValue>} & 0.50\\
            \texttt{<doping>} & 0.21\\
        \end{tabular}    
        \\ 
    \midrule
        2 & 0.65
        &\begin{tabular}{  cc  } 
            \texttt{<material>} & 0.75\\ 
            \texttt{<tc>} & 0.85\\
            \texttt{<tcValue>} & 0.85\\
            \texttt{<doping>} & 0.39 \\
        \end{tabular}          
        \\ 
    \midrule
        3 & 0.89
        & \begin{tabular}{  cc  } 
            \texttt{<material>} & 0.89\\ 
            \texttt{<tc>} & 0.91\\
            \texttt{<tcValue>} & 0.88\\
            \texttt{<doping>} & 0.94\\
        \end{tabular}       
        \\ 
    \bottomrule
    \end{tabular}}
    
    \label{table:summary-preliminary-annotation}
\end{table}


\begin{table}[ht]
     \tbl{Inconsistencies resulting from the overlapping of \texttt{<material>} and \texttt{<class>} labels.}
     {
    \begin{tabular}{ ccccc } 
    \toprule
        Text & Label 1 & \# & Label 2 & \#\\
    \midrule
        \texttt{superconducting transition}     &   \texttt{<material>}   &    1   &   \texttt{<tc>}  &   61   \\
        \texttt{NCCO}    &	\texttt{<material>}   &    14   &   \texttt{<tc>}  &   1   \\
        \texttt{superconducting transition temperatures}     &   \texttt{<material>}   &    1   &   \texttt{<tc>}  &   11   \\
        \texttt{occurrence of superconductivity}    &	\texttt{<material>}   &    1   &   \texttt{<tc>}  &   1   \\
    \bottomrule
    \end{tabular}}
    \label{table:dataset-inconsistencies-unclear}
\end{table}

\begin{table}[ht]
    \tbl{Inconsistencies resulting from human mistakes.}
    {\begin{tabular}{ ccccc } 
    \toprule
        Text & Label 1 & \# & Label 2 & \#\\
    \midrule
        \texttt{LiFeAs}         &   \texttt{<material>}   &    89   &   \texttt{<class>}  &   1   \\
        \texttt{Bi-2212}        &	\texttt{<material>}   &    34   &   \texttt{<class>}  &   1   \\
        \texttt{cobalt oxide}   &   \texttt{<material>}   &    89   &   \texttt{<class>}  &   1   \\
        \texttt{RE-123}         &	\texttt{<material>}   &    34   &   \texttt{<class>}  &   1   \\
    \bottomrule
    \end{tabular}}
    \label{table:dataset-inconsistencies-clear}
\end{table}


\begin{figure}[htb]
\centering
  \centering
  \includegraphics[width=0.5\linewidth]{workflow-schema}
  \caption{Annotation workflow. Different colours illustrate the involvement of each group at each step of the workflow.}
  \label{fig:schema-comparison-modified-workflow}
\end{figure}






\begin{table}[ht]
    \tbl{Statistical overview of the dataset. 
    Links\textsubscript{ip} indicates the number of links within the same paragraph (intra-paragraph). Links\textsubscript{ep} indicate the number of links from different paragraphs  (extra-paragraphs).  }
    {\begin{tabular}{ m{6em}   m{4em}  m{6em}  m{7em}  m{6em} } 
    \toprule
        \multirow{2}{5em}{\textbf{Documents}} & \textbf{Files} & \textbf{Paragraphs} &	\textbf{Sentences} & \textbf{Tokens}\\
         & 142  &	2800 & 	18344 & 	1118432\\
    \midrule
        \multirow{2}{5em}{\textbf{Entities}} & \textbf{Entities} &  \multicolumn{2}{|c|}{\textbf{Unique entities}} &  \textbf{ Labels} \\
        & 16040 &  \multicolumn{2}{c}{7151} &  6 \\
    \midrule
        \multirow{2}{5em}{\textbf{Links}} & \textbf{Links} & \multicolumn{2}{|c|}{\textbf{Links\textsubscript{ip}}} 
        & \textbf{Links\textsubscript{ep}}\\
        & 1399  & \multicolumn{2}{c}{1286} &	113	\\
    \bottomrule
    \end{tabular}}
    \label{table:summary-content}
\end{table}



\begin{figure}[htb]
    \centering
    \includegraphics[width=\linewidth]{data-transformation.png}
    \caption{Summary of the data transformation flows.}
    \label{fig:data-transformation}
\end{figure}


\begin{figure}[ht]
\centering
\subfloat[Papers distribution by Licence: Open Access vs copyrighted.]{\resizebox*{4cm}{!}{\includegraphics{papers-by-sources.png}}\label{fig:arxiv-rate}}
\hspace{5pt} 
\subfloat[Distribution by publisher.]{\resizebox*{4cm}{!}{\includegraphics{papers-by-publishers.png}}\label{fig:distribution-by-publisher}} 
\hspace{5pt} 
\subfloat[Distribution by year of publication.]{\resizebox*{4cm}{!}{\includegraphics{papers-by-years.png}}\label{fig:distribution-by-year}} 
\caption{Distribution of paper in the dataset by (a) license, (b) publisher, and (c) year of publication.} 
\label{fig:dataset-distributions}
\end{figure}


\begin{table}[ht]
    \tbl{Average IAA between the annotated and validated documents}
    {\begin{tabular}{ cc } 
    \toprule
        \textbf{Label} & \textbf{Average}\\
    \midrule
        \texttt{<material>}     &   0.956   \\
        \texttt{<me\_method>}   &	0.887   \\
        \texttt{<pressure>}     &	0.723   \\
        \texttt{<class>}        &	0.925   \\
        \texttt{<tcValue>}      &	0.863   \\
        \texttt{<tc>}           &	0.831   \\
    \midrule
        \textbf{Micro average}        &	0.911	\\
    \bottomrule
    \end{tabular}}
    
    \label{table:average-iaa}
\end{table}




\begin{figure}[htb]
    \centering
    \includegraphics[width=\linewidth]{inception-curation-new.png}
    \caption{INCEpTION curation interface. The example is taken from~\cite{Yonezawa2004NewO}.}
    \label{fig:inception-curation-interface}
\end{figure}








\begin{table}[ht]
     \tbl{Calculated IAA for annotations produced by domain experts, non-domain experts, and novices compared to the validated version. Annotations from domain experts are cross validated. }
    {\begin{tabular}{ ccccc } 
    \toprule
        \textbf{Label} & \textbf{Domain experts} & \textbf{Non-domain experts} & \textbf{Novices}\\
    \midrule
        \texttt{<material>}     &   0.969   & 0.950    &   0.924   \\
        \texttt{<me\_method>}   &   0.890   & 0.862    &   0.901   \\
        \texttt{<pressure>}     &   0.836   & 0.741    &   0.746   \\
        \texttt{<class>}        &   0.990   & 0.836	   &   0.899   \\
        \texttt{<tcValue>}      &   0.895   & 0.734	   &   0.841   \\
        \texttt{<tc>}           &   0.874   & 0.776	   &   0.830   \\
    \midrule
        \textbf{All labels}        &	0.940   &   0.882	&      0.896   \\
    \midrule
        \textbf{\# paragraphs}  &   1066   &  1648	    &   325     \\
    \bottomrule
    \end{tabular}}
   
    \label{table:comparison-iaa-nde-de}
\end{table}



% \begin{table}[ht]
%     \centering
%     \begin{tabular}{ | c | c| c| } 
%     \hline
%         \textbf{Iteration} \# & \textbf{IAA} & \textbf{IAA by label}  \\ [0.5ex] 
%     \hline
%         1  & 0.45
%         &\begin{tabular}{  c | c  } 
%             \texttt{<material>} & 0.45\\ 
%             \texttt{<tc>} & 0.56\\
%             \texttt{<tcValue>} & 0.50\\
%             \texttt{<doping>} & 0.21\\
%         \end{tabular}    
%         \\ 
%     \hline
%         2 & 0.65
%         &\begin{tabular}{  c |  c  } 
%             \texttt{<material>} & 0.75\\ 
%             \texttt{<tc>} & 0.85\\
%             \texttt{<tcValue>} & 0.85\\
%             \texttt{<doping>} & 0.39 \\
%         \end{tabular}          
%         \\ 
%     \hline
%         3 & 0.89
%         & \begin{tabular}{  c | c  } 
%             \texttt{<material>} & 0.89\\ 
%             \texttt{<tc>} & 0.91\\
%             \texttt{<tcValue>} & 0.88\\
%             \texttt{<doping>} & 0.94\\
%         \end{tabular}       
%         \\ 
%     \hline
%     \end{tabular}
%     \caption{Summary of the IAA for each annotation iteration.}
%     \label{table:summary-preliminary-annotation}
% \end{table}


% \begin{table}[ht]
%     \centering
%     \begin{tabular}{ | c | c | c | c | c | } 
%     \hline
%         \textbf{Text} & \textbf{Label 1} & \textbf{\#} & \textbf{Label 2} & \textbf{\#}\\
%     \hline
%         \texttt{LiFeAs}         &   \texttt{<material>}   &    89   &   \texttt{<class>}  &   1   \\
%         \texttt{Bi-2212}        &	\texttt{<material>}   &    34   &   \texttt{<class>}  &   1   \\
%         \texttt{cobalt oxide}   &   \texttt{<material>}   &    89   &   \texttt{<class>}  &   1   \\
%         \texttt{RE-123}         &	\texttt{<material>}   &    34   &   \texttt{<class>}  &   1   \\
%     \hline
%     \end{tabular}
%     \caption{Inconsistencies resulting from human mistakes.}
%     \label{table:dataset-inconsistencies-clear}
% \end{table}

% \begin{table}[ht]
%     \centering
%     \begin{tabular}{ | c | c | c | c | c | } 
%     \hline
%         \textbf{Text} & \textbf{Label 1} & \textbf{\#} & \textbf{Label 2} & \textbf{\#}\\
%     \hline
%         \texttt{superconducting transition}     &   \texttt{<material>}   &    1   &   \texttt{<tc>}  &   61   \\
%         \texttt{NCCO}    &	\texttt{<material>}   &    14   &   \texttt{<tc>}  &   1   \\
%         \texttt{superconducting transition temperatures}     &   \texttt{<material>}   &    1   &   \texttt{<tc>}  &   11   \\
%         \texttt{occurrence of superconductivity}    &	\texttt{<material>}   &    1   &   \texttt{<tc>}  &   1   \\
%     \hline
%     \end{tabular}
%     \caption{Inconsistencies resulting from the overlapping of \texttt{<material>} and \texttt{<class>} labels.}
%     \label{table:dataset-inconsistencies-unclear}
% \end{table}


% \begin{figure}[ht]
% \begin{subfigure}{0.3\textwidth}
%      \centering
%     \includegraphics[width=\linewidth]{papers-by-sources.png}
%     \captionof{figure}{Papers distribution by Licence: Open Access (CC-BY) vs copyrighted.}
%     \label{fig:arxiv-rate}
% \end{subfigure}
% \begin{subfigure}{0.4\textwidth}
%      \centering
%     \includegraphics[width=\linewidth]{papers-by-publishers.png}
%     \captionof{figure}{Distribution by publisher.}
%     \label{fig:distribution-by-publisher}
% \end{subfigure}
% \begin{subfigure}{0.3\textwidth}
% \centering
%     \includegraphics[width=\linewidth]{papers-by-years.png}
%     \captionof{figure}{Distribution by year of publication.}
%     \label{fig:distribution-by-year}
% \end{subfigure}
% \caption{Distribution of paper in the dataset by (a) license, (b) publisher, and (c) year of publication.}
% \label{fig:dataset-distributions}
% \end{figure}

% \begin{table}[ht]
%     \centering
%     \begin{tabular}{ |m{6em}  | m{4em} | m{6em} | m{7em} | m{6em} |} 
%     \hline
%         \multirow{2}{5em}{\textbf{Documents}} & \textbf{Files} & \textbf{Paragraphs} &	\textbf{Sentences} & \textbf{Tokens}\\
%          & 142  &	2800 & 	18344 & 	1118432\\
%     \hline\hline
%         \multirow{2}{5em}{\textbf{Entities}} & \textbf{Entities} &  \multicolumn{2}{|c|}{\textbf{Unique entities}} &  \textbf{ Labels} \\
%         & 16040 &  \multicolumn{2}{|c|}{7151} &  6 \\
%     \hline\hline
%         \multirow{2}{5em}{\textbf{Links}} & \textbf{Links} & \multicolumn{2}{|c|}{\textbf{Links\textsubscript{ip}}} 
%         & \textbf{Links\textsubscript{ep}}\\
%         & 1399  & \multicolumn{2}{|c|}{1286} &	113	\\
%     \hline
%     \end{tabular}
%     \caption{Statistical overview of the dataset. 
%     Links\textsubscript{ip} indicates the number of links within the same paragraph (intra-paragraph). Links\textsubscript{ep} indicate the number of links from different paragraphs  (extra-paragraphs).  }
%     \label{table:summary-content}
% \end{table}

% \begin{table}[ht]
%     \centering
%     \begin{tabular}{ | c | c | } 
%     \hline
%         \textbf{Label} & \textbf{Average}\\
%     \hline
%         \texttt{<material>}     &   0.956   \\
%         \texttt{<me\_method>}   &	0.887   \\
%         \texttt{<pressure>}     &	0.723   \\
%         \texttt{<class>}        &	0.925   \\
%         \texttt{<tcValue>}      &	0.863   \\
%         \texttt{<tc>}           &	0.831   \\
%     \hline
%         \textbf{Micro average}        &	0.911	\\
%     \hline
%     \end{tabular}
%     \caption{Average IAA between the annotated and validated documents}
%     \label{table:average-iaa}
% \end{table}

% \begin{table}[ht]
%     \centering
%     \begin{tabular}{ | c | c | c | c | c | } 
%     \hline
%         \textbf{Label} & \textbf{Domain experts} & \textbf{Non-domain experts} & \textbf{Novices}\\
%     \hline
%         \texttt{<material>}     &   0.969   & 0.950    &   0.924   \\
%         \texttt{<me\_method>}   &   0.890   & 0.862    &   0.901   \\
%         \texttt{<pressure>}     &   0.836   & 0.741    &   0.746   \\
%         \texttt{<class>}        &   0.990   & 0.836	   &   0.899   \\
%         \texttt{<tcValue>}      &   0.895   & 0.734	   &   0.841   \\
%         \texttt{<tc>}           &   0.874   & 0.776	   &   0.830   \\
%     \hline
%         \textbf{All labels}        &	0.940   &   0.882	&      0.896   \\
%     \hline
%         \textbf{\# paragraphs}  &   1066   &  1648	    &   325     \\
%     \hline
%     \end{tabular}
%     \caption{Calculated IAA for annotations produced by domain experts, non-domain experts, and novices compared to the validated version. Annotations from domain experts are cross validated. }
%     \label{table:comparison-iaa-nde-de}
% \end{table}

\end{document}
